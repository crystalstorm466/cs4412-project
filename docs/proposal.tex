\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{url}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{M1 Data Mining Project Proposal: Analyzing Reader Patterns and Genre Associations in the Goodreads Dataset*\\
{\footnotesize \textsuperscript{*} CS 4412: Data Mining}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} David Holland}
\IEEEauthorblockA{\textit{Student at Kennesaw State University} \\
Marietta GA \\
dholla36@students.kennesaw.edu}

}

\maketitle

\begin{abstract}
This proposal outlines a data mining project focused on the 2017 Goodreads dataset. This study aims to discover relationships between book genres, user behaviors, and how readers structure their reviews. We will be applying different techniques such as Association Rule Mining, K-Means Clustering, and Latent Dirichlet Allocation. This proposal seeks to understand how readers associate different genres in an attempt to define different segments of the reading community.
\end{abstract}

\begin{IEEEkeywords}
Data Mining, Goodreads, Association Rules, Clustering, Text Mining, Pattern Discovery
\end{IEEEkeywords}

\section{Introduction}
The digital age has transformed reading from a personal, solo activity into a social activity. Various platforms like Goodreads and Fable provide a massive database of user-generated data through ratings, reviews, and custom shelves. While many similar projects exist to predict user's rating there is more value in understanding how users engage with literature. This project focuses on the UCSD Goodreads dataset to find these patterns.

\section{Description}
This project will utilize the Goodreads Book Datasets (2017) curated by Julian McAuley at UCSD, Rishabh Misra and Ndapap Nakashole

\subsection{A. Source and Scale }
\begin{itemize}
    \item \textbf{Source:} \url{https://cseweb.ucsd.edu/~jmcauley/datasets/goodreads.html}
    \item \textbf{Size:} The full dataset contains metadata for 2.36 million books and 15.7 million detailed review texts. For this project, a subset (e.g., the "Young Adult" or "History" category) will be utilized to maintain computational feasibility while ensuring a sample size of over 100,000 records.
    \item \textbf{Format:} Data is provided in the CSV and json format, requiring significant preprocessing and flattening.
\end{itemize}

\subsection{Key Features and Schema}
The dataset is split into two primary components:
\begin{enumerate}
    \item \textbf{Metadata (\textit{goodreads\_books.json}):} Contains \texttt{book\_id}, \texttt{title}, \texttt{authors}, \texttt{average\_rating}, and importantly, \texttt{popular\_shelves} (user-defined tags).
    \item \textbf{Reviews (\textit{goodreads\_reviews.json}):} Contains \texttt{user\_id}, \texttt{book\_id}, \texttt{rating}, \texttt{review\_text}, and \texttt{n\_votes}.
    \item \textbf{User Interactions (\textit{goodreads\_interactions.csv}):} Contains \texttt{user\_id}, \texttt{book\_id}, \texttt{is\_read}, \texttt{rating}, and \texttt{is\_reviewed}.
\end{enumerate}


\section{C. Data Quality and Preprocessing}

Known issues include many user-defined shelves that share common tags like "to-read" and varying review lengths. This is most likely caused from Goodread's ability to easily add books to user's "to-read" shelve. Preprocessing will involve tokenization, stop-word removal for text mining and transforming the nested JSON shelves into a transaction-style for association mining.

\section{Discovery Questions}

This project moves beyond prediction models to investigate the following questions the team had:
\begin{itemize}
    \item What are the hidden associations between specfic book genres and user-defined "shelves"? (Do readers of "Romantasy (Romance Fantasy) also show high interset in "Historical Romance" or other fantsay genres?)
    \item Can we identify distinct Reader Personas based on interaction metrics? By clustering users based on their average rating variance, review frequency, and review length our goal is to discover if it is possible to classify readers as a critical reviewer or casual consumer.
    \item What type of patterns emerge from highly-voted reviews compared to low-voted ones? 
\end{itemize}

\section{Planned Techniques}
The analysis will follow a multistage data mining pipeline as visualized in Figure 1.

\begin{figure}[htbp]
  \centering
  \framebox{\parbox{0.45\textwidth}{\centering
    \vspace{1.5cm}
    \textbf{Analysis Pipeline Diagram} \\
    \small\textit{JSON Parsing $\rightarrow$ Cleaning $\rightarrow$ Feature Extraction $\rightarrow$ [Mining Modules] $\rightarrow$ Evaluation}
    \vspace{1.5cm}
  }}
  \caption{Planned Data Mining Workflow.}
  \label{fig:pipeline}
\end{figure}

\subsection{Association Rule Mining (FP-Growth)}\label{AA}
    We will treat each user's shelves as a transaction. Using the FP-Growth Algorithm to discover rules with high lift and confidence to identify non-obvious genre relationships. Our goal is to move beyond the standard "Fantasy" label and discover more sub-genre patterns.
\subsection{Clustering (K-Means)}
    To answer the second discovery question, we will apply K-Means clustering on standarized numerical features derived the user dataset. We will be using the "Elbow Method" and "Silhoutette Score" to determine the optimal number of reader segments.
\subsection{Text Mining (LDA - Topic Modeling)}
    Using the Latent Dirichlet Allocation (LDA) algorithm, we will perform topic modeling on the \texttt{review\_text}. This will allow us to discover the primary topics of discussion within different genres without pre-defining what those topics are.

\section {Preliminary Timeline}
The project will proceed according to the following milestones

\begin{table}[htbp]
\caption{Project Milestone Timeline}
\begin{center}
\begin{tabular}{@{}llp{4.5cm}@{}}
\toprule
\textbf{Milestone} & \textbf{Period} & \textbf{Key Activities} \\ \midrule
M2 & Weeks 8 & Applying KDD process and Association Rule Mining \\
M3 & Weeks 11 & Clustering Analyses, Classification Techniques, detecting Anomalies, and Communicating results \\
M4 & Weeks 14 & Text Mining (LDA), Final Report \\ \bottomrule
\end{tabular}
\end{center}
\end{table}
\subsection{Anticipated Challenges}
\begin{itemize}
    \item   Our primary challenge is lack of experience in analyzing data sets. 
    \item Another challene is the volume of data. The Goodreads dataset is comprised of multiple csv and jsons files that is multiple gigabytes compressed. Handling this in local memory will require using pandas chunking or focusing on smaller genre subsets. Text data can also be "noisy" and will require filtering to produce meaningful topics. 
\end{itemize}
  
    
\section*{Acknowledgment}
The author would like to thank Julian McAuley for providing the Goodreads dataset and Kennesaw State University for the computational resources.

\begin{thebibliography}{00}
\bibitem{b1} Mengting Wan, Julian McAuley, "Item Recommendation on Monotonic Behavior Chains", in RecSys'18. 
\bibitem{b2} Mengting Wan, Rishabh Misra, Ndapa Nakashole, Julian McAuley, "Fine-Grained Spoiler Detection from Large-Scale Review Corpora", in ACL'19

\end{thebibliography}

\end{document}
