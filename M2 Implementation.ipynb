{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a36a04-3174-4fb9-bac0-75671e636f28",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "The goal of the M2 is to explore the hidden associations between specific book genres and user-defined shelves. We also want to try to identify distrinct Reader Personas based on interaction metrics through clustering users based on their \"average rating variance\", rating frequency, and review length to classify readers \"critical reviewer\" or \"casual consumer\"\n",
    "\n",
    "What type of patterns emerge from highly-voted reviews compared to low-voted ones?\n",
    "\n",
    "# Data loading & Subsetting\n",
    "\n",
    "1. Load `romantasay_books_subset.json` - Created from scripts/main.py\n",
    "2. Steam and filter `goodreads_reviews_dedup.json` to match book subset\n",
    "3. Load a chunk of `goodreads_interactions.csv`  to calculate user-level metrics\n",
    "\n",
    "# Data Quality & Cleaning\n",
    "\n",
    "- Use langid to ensure review text is English only\n",
    "- Remove \"to-read\", \"owned\", and \"kindle\" tags that skew associaiton rules\n",
    "\n",
    "# EDA Visualizations\n",
    "\n",
    "- Genre/Shelf Analysis\n",
    "- Persona Distributions: Histogram of rating variance ot seed if most readers are \"nice\" high ratings or \"critical\"\n",
    "  - Scatter plot\" `review length` vs `rating_frequency`\n",
    "- Vote Analysis: Box plots comparing `review_length` across different `n_votes` tiers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e724ec04-3f6f-48e3-928c-f06ae192e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print('hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88b9519-6881-4895-8f2a-239072361d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, Tim!'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def say_hello(recipient):\n",
    "    return 'Hello, {}!'.format(recipient)\n",
    "say_hello('Tim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f831091-3f4d-41f6-adf1-fdab75f7f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def square(x):\n",
    "    return x * x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "940f6a6b-0e4b-439b-9327-334839e0b0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 squared is 64\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(1,10)\n",
    "y = square(x)\n",
    "\n",
    "print('%d squared is %d'% (x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e27828-2b08-472a-b3ea-333bc2a96287",
   "metadata": {},
   "source": [
    "1. Create ouput.json and filter out books in the dataset that match Romantasy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdb3f86b-667c-490f-9018-6d90fe1883a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting filtration of data/goodreads_books.json.gz...\n",
      "Processed 100000 books... Saved 910 matches.\n",
      "Processed 200000 books... Saved 1854 matches.\n",
      "Processed 300000 books... Saved 2816 matches.\n",
      "Processed 400000 books... Saved 3747 matches.\n",
      "Processed 500000 books... Saved 4654 matches.\n",
      "Processed 600000 books... Saved 5594 matches.\n",
      "Processed 700000 books... Saved 6485 matches.\n",
      "Processed 800000 books... Saved 7440 matches.\n",
      "Processed 900000 books... Saved 8388 matches.\n",
      "Processed 1000000 books... Saved 9300 matches.\n",
      "Processed 1100000 books... Saved 10168 matches.\n",
      "Processed 1200000 books... Saved 11093 matches.\n",
      "Processed 1300000 books... Saved 12000 matches.\n",
      "Processed 1400000 books... Saved 12948 matches.\n",
      "Processed 1500000 books... Saved 13861 matches.\n",
      "Processed 1600000 books... Saved 14758 matches.\n",
      "Processed 1700000 books... Saved 15716 matches.\n",
      "Processed 1800000 books... Saved 16646 matches.\n",
      "Processed 1900000 books... Saved 17545 matches.\n",
      "Processed 2000000 books... Saved 18455 matches.\n",
      "Processed 2100000 books... Saved 19393 matches.\n",
      "Processed 2200000 books... Saved 20243 matches.\n",
      "Processed 2300000 books... Saved 21170 matches.\n",
      "Done! Processed 2360655 total books. Saved 21741 to data/output.json.\n"
     ]
    }
   ],
   "source": [
    "%run scripts/main.py data/goodreads_books.json.gz data/output.json "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde7f55-127d-4d3c-b976-0d6e3d67f32d",
   "metadata": {},
   "source": [
    "2. Discover what genres or \"shelves\" are most frequently group together by readers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b40a19a3-3517-4cd3-a4fa-fe7b5a7226db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting transactions from data/output.json...\n",
      "Done! Saved 15239 transactions to data/temp.csv.\n",
      "Loading transactions from data/temp.csv into memory...\n",
      "Encoding 15239 transactions into a Sparse Matrix...\n",
      "Running FP-Growth (min_support=0.08)...\n",
      "Generating association rules...\n",
      "\n",
      "--- Top 10 Discovered Patterns (by Lift) ---\n",
      "                               antecedents  \\\n",
      "69587              frozenset({ya-fiction})   \n",
      "69582        frozenset({ya-fantasy, teen})   \n",
      "69583  frozenset({ya-fantasy, ya-fiction})   \n",
      "69586                    frozenset({teen})   \n",
      "69578           frozenset({romance, teen})   \n",
      "69581              frozenset({ya-fiction})   \n",
      "69488                    frozenset({teen})   \n",
      "69489              frozenset({ya-fiction})   \n",
      "69580                    frozenset({teen})   \n",
      "69579     frozenset({romance, ya-fiction})   \n",
      "\n",
      "                               consequents      lift   support  \n",
      "69587        frozenset({ya-fantasy, teen})  9.422761  0.081305  \n",
      "69582              frozenset({ya-fiction})  9.422761  0.081305  \n",
      "69583                    frozenset({teen})  8.769065  0.081305  \n",
      "69586  frozenset({ya-fantasy, ya-fiction})  8.769065  0.081305  \n",
      "69578              frozenset({ya-fiction})  8.744835  0.081633  \n",
      "69581           frozenset({romance, teen})  8.744835  0.081633  \n",
      "69488              frozenset({ya-fiction})  8.703019  0.081633  \n",
      "69489                    frozenset({teen})  8.703019  0.081633  \n",
      "69580     frozenset({romance, ya-fiction})  8.703019  0.081633  \n",
      "69579                    frozenset({teen})  8.703019  0.081633  \n",
      "Results saved to data/output.csv\n"
     ]
    }
   ],
   "source": [
    "%run scripts/data.py data/output.json data/temp.csv data/output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dbeaf2e-1a20-459b-a5ee-b0543531e81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting filtration of data/goodreads_reviews_dedup.json.gz...\n",
      "Processed 100000 books... Saved 0 matches.\n",
      "Processed 200000 books... Saved 0 matches.\n",
      "Processed 300000 books... Saved 0 matches.\n",
      "Processed 400000 books... Saved 0 matches.\n",
      "Processed 500000 books... Saved 0 matches.\n",
      "Processed 600000 books... Saved 0 matches.\n",
      "Processed 700000 books... Saved 0 matches.\n",
      "Processed 800000 books... Saved 0 matches.\n",
      "Processed 900000 books... Saved 0 matches.\n",
      "Processed 1000000 books... Saved 0 matches.\n",
      "Processed 1100000 books... Saved 0 matches.\n",
      "Processed 1200000 books... Saved 0 matches.\n",
      "Processed 1300000 books... Saved 0 matches.\n",
      "Processed 1400000 books... Saved 0 matches.\n",
      "Processed 1500000 books... Saved 0 matches.\n",
      "Processed 1600000 books... Saved 0 matches.\n",
      "Processed 1700000 books... Saved 0 matches.\n",
      "Processed 1800000 books... Saved 0 matches.\n",
      "Processed 1900000 books... Saved 0 matches.\n",
      "Processed 2000000 books... Saved 0 matches.\n",
      "Processed 2100000 books... Saved 0 matches.\n",
      "Processed 2200000 books... Saved 0 matches.\n",
      "Processed 2300000 books... Saved 0 matches.\n",
      "Processed 2400000 books... Saved 0 matches.\n",
      "Processed 2500000 books... Saved 0 matches.\n",
      "Processed 2600000 books... Saved 0 matches.\n",
      "Processed 2700000 books... Saved 0 matches.\n",
      "Processed 2800000 books... Saved 0 matches.\n",
      "Processed 2900000 books... Saved 0 matches.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/KSU Spring 2026/Data Mining/cs4412-project/scripts/main.py:50\u001b[39m\n\u001b[32m     48\u001b[39m output_file = sys.argv[\u001b[32m2\u001b[39m];\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(input_file):\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[43mfilter_goodreads_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found. Please download it first.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/KSU Spring 2026/Data Mining/cs4412-project/scripts/main.py:22\u001b[39m, in \u001b[36mfilter_goodreads_data\u001b[39m\u001b[34m(input_path, output_path, target_keywords)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fin:\n\u001b[32m     21\u001b[39m     count += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     book = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# Extract tags from the popular_shelves list of dictionaries\u001b[39;00m\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# Structure: [{'count': '123', 'name': 'fantasy'}, ...]\u001b[39;00m\n\u001b[32m     26\u001b[39m     shelves = [s[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m].lower() \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m book.get(\u001b[33m'\u001b[39m\u001b[33mpopular_shelves\u001b[39m\u001b[33m'\u001b[39m, [])]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.14/json/__init__.py:352\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    347\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    350\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    351\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    354\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.14/json/decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    341\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m     end = _w(s, end).end()\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.14/json/decoder.py:361\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    358\u001b[39m \n\u001b[32m    359\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%run scripts/main.py data/goodreads_reviews_dedup.json.gz data/output.json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ab94e-80d3-4beb-8cd0-6c6b3cdfb5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
